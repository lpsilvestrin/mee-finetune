{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def download_model_residuals():\n",
    "    api = wandb.Api()\n",
    "\n",
    "    src_datsets = ['src', 'bpm10_src', 'bike11_src']\n",
    "    # fitler out the pre-training runs\n",
    "    filters = {\n",
    "        \"$and\": [\n",
    "            {\"config.train_dataset\": {\"$nin\": src_datsets}}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    runs = api.runs(\"transfer-learning-tcn/tcn_custom_loss_residuals\",\n",
    "                    filters=filters,\n",
    "                    order=\"-created_at\")\n",
    "\n",
    "    config_list = []\n",
    "    runs_df = pd.DataFrame()\n",
    "    residuals = dict()\n",
    "    if os.path.exists(\"tcn_custom_loss_residuals.npz\"):\n",
    "        residuals.update(**np.load(\"tcn_custom_loss_residuals.npz\", allow_pickle=True))\n",
    "        runs_df = pd.read_csv(\"tcn_custom_loss_residuals.csv\")\n",
    "    for run in tqdm(runs):\n",
    "        global_id = run.name + '-' + run.id\n",
    "        if global_id in residuals:\n",
    "            continue\n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files\n",
    "        summary = {k: v for k, v in run.summary._json_dict.items()\n",
    "                   if not k.startswith('_') and\n",
    "                   not type(v) is list and\n",
    "                   not type(v) is dict}\n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        conf = {k: v for k,v in run.config.items()\n",
    "                if not k.startswith('_')}\n",
    "        conf.update(summary)\n",
    "        conf['timestamp'] = run.summary['_timestamp']\n",
    "        # .name is the human-readable name of the run.\n",
    "        conf['wandb_name'] = run.name\n",
    "        conf['wandb_id'] = run.id\n",
    "        conf['global_id'] = global_id\n",
    "        conf['tags'] = \",\".join(run.tags)\n",
    "        config_list.append(conf)\n",
    "        # download the residuals\n",
    "        res = wandb.restore('test_test_residuals.npy', run_path=\"/\".join(run.path), replace=True)\n",
    "        residuals[global_id] = np.load(res.name)\n",
    "\n",
    "    runs_df = pd.concat([runs_df, pd.DataFrame(config_list)], axis=0)\n",
    "    return runs_df, residuals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def download_sota_tl_results():\n",
    "    api = wandb.Api()\n",
    "\n",
    "    filters = {\n",
    "        \"$and\": [\n",
    "            {\"state\": 'finished'},\n",
    "            {\"tags\": {\"$in\": [\"normalized_labels\"]}}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    def parse_runs(wandb_proj, previous_ids):\n",
    "        runs = api.runs(wandb_proj,\n",
    "                    filters=filters,\n",
    "                    order=\"-created_at\")\n",
    "        config_list = []\n",
    "        for run in tqdm(runs):\n",
    "\n",
    "            global_id = run.name + '-' + run.id\n",
    "            if global_id in previous_ids:\n",
    "                continue\n",
    "            # .summary contains the output keys/values for metrics like accuracy.\n",
    "            #  We call ._json_dict to omit large files\n",
    "            summary = {k: v for k, v in run.summary._json_dict.items()\n",
    "                       if not k.startswith('_') and\n",
    "                       not type(v) is list and\n",
    "                       not type(v) is dict}\n",
    "            # .config contains the hyperparameters.\n",
    "            #  We remove special values that start with _.\n",
    "            conf = {k: v for k,v in run.config.items()\n",
    "                    if not k.startswith('_')}\n",
    "            conf.update(summary)\n",
    "            conf['timestamp'] = run.summary['_timestamp']\n",
    "            # .name is the human-readable name of the run.\n",
    "            conf['wandb_name'] = run.name\n",
    "            conf['wandb_id'] = run.id\n",
    "            conf['global_id'] = global_id\n",
    "            conf['tags'] = \",\".join(run.tags)\n",
    "\n",
    "            # store evaluation performance under default column test/mse(mae)\n",
    "            if 'test/mse' not in conf:\n",
    "                conf['test/mse'] = conf['test/loss']\n",
    "\n",
    "            config_list.append(conf)\n",
    "        return pd.DataFrame(config_list)\n",
    "\n",
    "    runs_df = pd.DataFrame()\n",
    "    prev_ids = []\n",
    "    if os.path.exists(\"sota_results.csv\"):\n",
    "        runs_df = pd.read_csv(\"sota_results.csv\")\n",
    "        prev_ids = list(runs_df['global_id'])\n",
    "\n",
    "    runs_wann = parse_runs(\"transfer-learning-tcn/wann\", prev_ids)\n",
    "    runs_trb = parse_runs(\"transfer-learning-tcn/tradaboostr2-nn\", prev_ids)\n",
    "    runs_wann['approach'] = 'WANN'\n",
    "    runs_trb['approach'] = 'TRB'\n",
    "    runs_df = pd.concat([runs_df, runs_wann, runs_trb], axis=0)\n",
    "    return runs_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def approach_rename(inputs):\n",
    "    name_convertion = dict(\n",
    "        MI='MI',\n",
    "        MSE='MSL',\n",
    "        MAE='MAL',\n",
    "        MEE='MEE',\n",
    "        HSIC='HSIC',\n",
    "        NAN='baseline'\n",
    "    )\n",
    "    name = \"-\".join([name_convertion[str(n).upper()] for n in inputs])\n",
    "    return name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# TODO: run the download again to combine all the results\n",
    "download = False\n",
    "if download:\n",
    "    residual_df, residuals = download_model_residuals()\n",
    "    residual_df['approach'] = residual_df[['loss_src', 'loss_function']].apply(approach_rename, axis=1)\n",
    "    # append sota result to the existing df\n",
    "    sota_df = download_sota_tl_results()\n",
    "\n",
    "    # save wandb downloaded data\n",
    "    np.savez(\"tcn_custom_loss_residuals\", **residuals)\n",
    "    residual_df.to_csv(\"tcn_custom_loss_residuals.csv\")\n",
    "    sota_df.to_csv(\"sota_results.csv\")\n",
    "else:\n",
    "    residual_df = pd.read_csv(\"tcn_custom_loss_residuals.csv\")\n",
    "    residuals = np.load(\"tcn_custom_loss_residuals.npz\", allow_pickle=True)\n",
    "    sota_df = pd.read_csv(\"sota_results.csv\")\n",
    "residual_df = pd.concat([residual_df, sota_df], axis=0).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "505"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(~residual_df['tags'].isna())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# filter linear pruning results to separate dataframe\n",
    "linear_prune_df = residual_df[~residual_df['tags'].isna() & residual_df['tags'].str.contains(\"linear_pruning\")]\n",
    "residual_df = residual_df.drop(linear_prune_df.index, axis=\"index\")\n",
    "# append baselines to the linear_prune df\n",
    "linear_prune_df = pd.concat([linear_prune_df, residual_df[residual_df['approach'].str.contains('baseline')]])\n",
    "linear_prune_df = linear_prune_df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "baseline-MEE     105\nbaseline-HSIC    105\nbaseline-MAL     105\nbaseline-MSL     105\nMSL-MAL          100\nMAL-MSL          100\nHSIC-MSL         100\nMSL-MEE          100\nHSIC-HSIC        100\nMEE-MSL          100\nMEE-MEE          100\nMAL-MAL          100\nMSL-HSIC         100\nMSL-MSL          100\nWANN              55\nTRB               50\nName: approach, dtype: int64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_df['approach'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "baseline-MEE     105\nbaseline-HSIC    105\nbaseline-MAL     105\nbaseline-MSL     105\nMSL-HSIC         100\nMSL-MAL          100\nMSL-MSL          100\nMSL-MEE          100\nName: approach, dtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_prune_df['approach'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table overview of the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "import re\n",
    "def table_sota_comparison(result_df, methods, main, metric='test/mse'):\n",
    "    all_methods = methods + [main]\n",
    "    res = result_df[['approach', 'train_dataset', metric, 'seed']][result_df['approach'].isin(all_methods)]\n",
    "\n",
    "    # renaming datasets\n",
    "    new_ds_names = dict(\n",
    "        bike11_tar=\"BKT\",\n",
    "        bpm10_tar=\"PMT\",\n",
    "        tar1=\"NT1\",\n",
    "        tar2=\"NT2\",\n",
    "        tar3=\"NT3\",\n",
    "    )\n",
    "    res['train_dataset'] = res['train_dataset'].apply(lambda n: new_ds_names[n])\n",
    "    res = res.sort_values('train_dataset')\n",
    "\n",
    "    datasets = res['train_dataset'].unique()\n",
    "    res = res[res['seed'] < 20] # remove extra seed of the baselines\n",
    "    res = pd.pivot_table(res, values=metric, index=['train_dataset', 'seed'], columns=['approach'])\n",
    "\n",
    "    # res = res.pivot(index='seed', columns='approach', values=['test/mse', 'train_dataset'])\n",
    "    grouped = res.groupby('train_dataset').agg(['mean', 'std'])\n",
    "    # latex_table = grouped[all_methods].to_latex(float_format=\"%.2g\")\n",
    "    latex_table = grouped[all_methods].style.format('{:.2g}').to_latex()\n",
    "\n",
    "    latex_table = re.sub(\"&([\\s0-9\\-.+e]+)&([\\s0-9\\-.+e]+)\", r\"&\\1$\\\\pm$\\2\", latex_table)\n",
    "\n",
    "    print(latex_table)\n",
    "\n",
    "    # methods = ['ols', 'dsft', 'dsft_nl', 'dp']\n",
    "    # main = 'dp'\n",
    "    # methods.remove(main)\n",
    "    p_val_adjustment = len(methods)\n",
    "\n",
    "    def wilcox(m1, m2):\n",
    "        stat, p = wilcoxon(m1, m2)\n",
    "        mean1 = np.mean(m1)\n",
    "        mean2 = np.mean(m2)\n",
    "        if p >= 0.05 / p_val_adjustment:\n",
    "        # if p >= 0.05:\n",
    "            test_result = '?'\n",
    "        elif mean1 < mean2:\n",
    "            test_result = 'v'\n",
    "        else:\n",
    "            test_result = 'x'\n",
    "        return test_result\n",
    "\n",
    "    def test_all_methods(results, test):\n",
    "        return [test(results[main], results[m]) for m in methods]\n",
    "    res = res.reset_index()\n",
    "    tresults = [[d] + test_all_methods(res[res['train_dataset']==d], wilcox) for d in datasets]\n",
    "\n",
    "    columns = ['dataset'] + [f\"{main} x {m}\" for m in methods]\n",
    "    print(pd.DataFrame(tresults, columns=columns))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparing methods for pre-training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "approach & \\multicolumn{2}{r}{MSL-MSL} & \\multicolumn{2}{r}{MAL-MSL} & \\multicolumn{2}{r}{HSIC-MSL} & \\multicolumn{2}{r}{MEE-MSL} \\\\\n",
      " & mean & std & mean & std & mean & std & mean & std \\\\\n",
      "train_dataset &  $\\pm$  &  $\\pm$  &  $\\pm$  &  $\\pm$  \\\\\n",
      "BKT & 0.16 $\\pm$ 0.015 & 0.16 $\\pm$ 0.014 & 0.25 $\\pm$ 0.044 & 0.16 $\\pm$ 0.012 \\\\\n",
      "NT1 & 0.47 $\\pm$ 0.0083 & 0.48 $\\pm$ 0.0097 & 0.48 $\\pm$ 0.0099 & 0.47 $\\pm$ 0.012 \\\\\n",
      "NT2 & 0.59 $\\pm$ 0.013 & 0.59 $\\pm$ 0.012 & 0.61 $\\pm$ 0.017 & 0.59 $\\pm$ 0.012 \\\\\n",
      "NT3 & 0.45 $\\pm$ 0.0072 & 0.45 $\\pm$ 0.0062 & 0.46 $\\pm$ 0.0054 & 0.45 $\\pm$ 0.0073 \\\\\n",
      "PMT & 0.44 $\\pm$ 0.042 & 0.45 $\\pm$ 0.046 & 0.46 $\\pm$ 0.041 & 0.45 $\\pm$ 0.033 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "  dataset MEE-MSL x MSL-MSL MEE-MSL x MAL-MSL MEE-MSL x HSIC-MSL\n",
      "0     BKT                 ?                 ?                  v\n",
      "1     NT1                 ?                 ?                  ?\n",
      "2     NT2                 ?                 ?                  v\n",
      "3     NT3                 ?                 ?                  v\n",
      "4     PMT                 ?                 ?                  ?\n"
     ]
    }
   ],
   "source": [
    "table_sota_comparison(residual_df , ['MSL-MSL', 'MAL-MSL', 'HSIC-MSL'], main='MEE-MSL')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparing methods for fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "approach & \\multicolumn{2}{r}{MSL-MSL} & \\multicolumn{2}{r}{MSL-MAL} & \\multicolumn{2}{r}{MSL-HSIC} & \\multicolumn{2}{r}{MSL-MEE} \\\\\n",
      " & mean & std & mean & std & mean & std & mean & std \\\\\n",
      "train_dataset &  $\\pm$  &  $\\pm$  &  $\\pm$  &  $\\pm$  \\\\\n",
      "BKT & 0.16 $\\pm$ 0.015 & 0.17 $\\pm$ 0.018 & 0.16 $\\pm$ 0.018 & 0.16 $\\pm$ 0.012 \\\\\n",
      "NT1 & 0.47 $\\pm$ 0.0083 & 0.48 $\\pm$ 0.0081 & 0.48 $\\pm$ 0.008 & 0.46 $\\pm$ 0.0074 \\\\\n",
      "NT2 & 0.59 $\\pm$ 0.013 & 0.58 $\\pm$ 0.012 & 0.58 $\\pm$ 0.012 & 0.59 $\\pm$ 0.0089 \\\\\n",
      "NT3 & 0.45 $\\pm$ 0.0072 & 0.45 $\\pm$ 0.0065 & 0.45 $\\pm$ 0.0067 & 0.44 $\\pm$ 0.0058 \\\\\n",
      "PMT & 0.44 $\\pm$ 0.042 & 0.44 $\\pm$ 0.038 & 0.47 $\\pm$ 0.034 & 0.46 $\\pm$ 0.024 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "  dataset MSL-MEE x MSL-MSL MSL-MEE x MSL-MAL MSL-MEE x MSL-HSIC\n",
      "0     BKT                 ?                 ?                  ?\n",
      "1     NT1                 v                 v                  v\n",
      "2     NT2                 ?                 x                  x\n",
      "3     NT3                 v                 v                  v\n",
      "4     PMT                 ?                 ?                  ?\n"
     ]
    }
   ],
   "source": [
    "table_sota_comparison(residual_df , ['MSL-MSL', 'MSL-MAL', 'MSL-HSIC'], main='MSL-MEE')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparing methods for pre-training + fine-tuning\n",
    "### MSE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrr}\n",
      "approach & \\multicolumn{2}{r}{baseline-MEE} & \\multicolumn{2}{r}{MSL-MSL} & \\multicolumn{2}{r}{MAL-MAL} & \\multicolumn{2}{r}{HSIC-HSIC} & \\multicolumn{2}{r}{MEE-MEE} \\\\\n",
      " & mean & std & mean & std & mean & std & mean & std & mean & std \\\\\n",
      "train_dataset &  $\\pm$  &  $\\pm$  &  $\\pm$  &  $\\pm$  &  $\\pm$  \\\\\n",
      "BKT & 0.41 $\\pm$ 0.028 & 0.16 $\\pm$ 0.015 & 0.16 $\\pm$ 0.014 & 0.26 $\\pm$ 0.065 & 0.16 $\\pm$ 0.014 \\\\\n",
      "NT1 & 0.46 $\\pm$ 0.007 & 0.47 $\\pm$ 0.0083 & 0.48 $\\pm$ 0.01 & 0.48 $\\pm$ 0.0085 & 0.45 $\\pm$ 0.0075 \\\\\n",
      "NT2 & 0.59 $\\pm$ 0.019 & 0.59 $\\pm$ 0.013 & 0.57 $\\pm$ 0.012 & 0.59 $\\pm$ 0.013 & 0.59 $\\pm$ 0.013 \\\\\n",
      "NT3 & 0.45 $\\pm$ 0.0057 & 0.45 $\\pm$ 0.0072 & 0.45 $\\pm$ 0.0068 & 0.45 $\\pm$ 0.0081 & 0.44 $\\pm$ 0.0053 \\\\\n",
      "PMT & 0.52 $\\pm$ 0.036 & 0.44 $\\pm$ 0.042 & 0.45 $\\pm$ 0.049 & 0.52 $\\pm$ 0.039 & 0.47 $\\pm$ 0.021 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "  dataset MEE-MEE x baseline-MEE MEE-MEE x MSL-MSL MEE-MEE x MAL-MAL  \\\n",
      "0     BKT                      v                 ?                 ?   \n",
      "1     NT1                      ?                 v                 v   \n",
      "2     NT2                      ?                 ?                 ?   \n",
      "3     NT3                      v                 v                 v   \n",
      "4     PMT                      v                 x                 ?   \n",
      "\n",
      "  MEE-MEE x HSIC-HSIC  \n",
      "0                   v  \n",
      "1                   v  \n",
      "2                   ?  \n",
      "3                   v  \n",
      "4                   v  \n"
     ]
    }
   ],
   "source": [
    "table_sota_comparison(residual_df , ['baseline-MEE', 'MSL-MSL', 'MAL-MAL', 'HSIC-HSIC'], main='MEE-MEE', metric='test/mse')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "table_sota_comparison(residual_df , ['baseline-MEE', 'MSL-MSL', 'MAL-MAL', 'HSIC-HSIC'], main='MEE-MEE', metric='test/mae')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison on target-only (no TL)\n",
    "#### MSE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "table_sota_comparison(residual_df , ['baseline-MSL', 'baseline-MAL', 'baseline-HSIC'], main='baseline-MEE', metric='test/mse')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "table_sota_comparison(residual_df , ['baseline-MSL', 'baseline-MAL', 'baseline-HSIC'], main='baseline-MEE', metric='test/mae')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear probing comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "approach & \\multicolumn{2}{r}{MSL-MSL} & \\multicolumn{2}{r}{MSL-MAL} & \\multicolumn{2}{r}{MSL-HSIC} & \\multicolumn{2}{r}{MSL-MEE} \\\\\n",
      " & mean & std & mean & std & mean & std & mean & std \\\\\n",
      "train_dataset &  $\\pm$  &  $\\pm$  &  $\\pm$  &  $\\pm$  \\\\\n",
      "BKT & 0.25 $\\pm$ 0.029 & 0.26 $\\pm$ 0.04 & 0.26 $\\pm$ 0.031 & 0.24 $\\pm$ 0.031 \\\\\n",
      "NT1 & 0.87 $\\pm$ 0.016 & 0.9 $\\pm$ 0.0092 & 0.89 $\\pm$ 0.025 & 0.87 $\\pm$ 0.018 \\\\\n",
      "NT2 & 0.48 $\\pm$ 0.024 & 0.48 $\\pm$ 0.029 & 0.54 $\\pm$ 0.047 & 0.49 $\\pm$ 0.025 \\\\\n",
      "NT3 & 0.72 $\\pm$ 0.022 & 0.73 $\\pm$ 0.018 & 0.73 $\\pm$ 0.015 & 0.7 $\\pm$ 0.0092 \\\\\n",
      "PMT & 0.57 $\\pm$ 0.039 & 0.56 $\\pm$ 0.036 & 0.63 $\\pm$ 0.038 & 0.54 $\\pm$ 0.034 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "  dataset MSL-MEE x MSL-MSL MSL-MEE x MSL-MAL MSL-MEE x MSL-HSIC\n",
      "0     BKT                 v                 v                  v\n",
      "1     NT1                 v                 v                  v\n",
      "2     NT2                 ?                 ?                  v\n",
      "3     NT3                 v                 v                  v\n",
      "4     PMT                 v                 v                  v\n"
     ]
    }
   ],
   "source": [
    "table_sota_comparison(linear_prune_df, ['MSL-MSL', 'MSL-MAL', 'MSL-HSIC'], main='MSL-MEE', metric='test/mse')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison with SOTA TL methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "table_sota_comparison(residual_df[residual_df['seed'] <= 10], ['MSL-MSL', 'TRB', 'WANN'], main='MEE-MEE')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "residual_df[residual_df['approach']=='baseline-MAL']['train_dataset'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "residual_df['approach'].value_counts().head(20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(residual_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# wandb_data = residual_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def merge_residuals_and_metadata(df, res_dict, filter=None):\n",
    "    if filter is not None:\n",
    "        df = df[filter]\n",
    "    res_list = [res_dict[name] for name in df['wandb_name']]\n",
    "    lengths = [len(x) for x in res_list]\n",
    "    meta = np.repeat(np.array(df[['approach', 'train_dataset']]), lengths, axis=0)\n",
    "    res_np = np.concatenate(res_list)\n",
    "    merged = pd.DataFrame(np.concatenate([meta, res_np], axis=1), columns=['approach', 'train_dataset', 'residuals'])\n",
    "    merged.sort_values(by=['approach'])\n",
    "    return merged"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_approaches(dataframe, dataset='tar1', approaches=[]):\n",
    "    filter = dataframe['train_dataset'].str.contains(dataset)\n",
    "    if len(approaches) == 0:\n",
    "        return filter\n",
    "    ap_filter = [False for _ in range(len(filter))]\n",
    "    for ap in approaches:\n",
    "        ap_filter = ap_filter | dataframe['approach'].str.contains(ap)\n",
    "    return filter & ap_filter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "def plot_boxplots(wandb_df, dataset_name):\n",
    "\n",
    "    filter_df = wandb_df[wandb_df['train_dataset'].str.contains(dataset_name)]\n",
    "    filtered_approaches = ['HSIC-MSL', 'MEE-MSL']\n",
    "    filter_df = filter_df[~filter_df['approach'].isin(filtered_approaches)]\n",
    "    palette = sns.color_palette(\"Paired\", len(filter_df['approach'].unique()))\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    sns.boxplot(\n",
    "        x='approach', y='test/mse',\n",
    "        data=filter_df.sort_values('approach'),\n",
    "        ax=axes[0],\n",
    "        showmeans=True,\n",
    "        meanprops={\"marker\": \"x\", \"markeredgecolor\": \"black\"},\n",
    "        palette=palette)\n",
    "    sns.boxplot(\n",
    "        x='approach', y='test/mae',\n",
    "        data=filter_df.sort_values('approach'),\n",
    "        ax=axes[1],\n",
    "        showmeans=True,\n",
    "        meanprops={\"marker\": \"x\", \"markeredgecolor\": \"black\"},\n",
    "        palette=palette)\n",
    "    for i, ax in enumerate(axes):\n",
    "        plt.sca(ax)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.xlabel(\"Train/finetune loss function\")\n",
    "        if i == 0:\n",
    "            plt.ylabel(\"Test MSE\")\n",
    "        else:\n",
    "            plt.ylabel(\"Test MAE\")\n",
    "    plt.savefig(f\"plots/{dataset_name}_boxplots.pdf\", bbox_inches='tight', format='pdf', dpi=300)\n",
    "\n",
    "def plot_histograms(wandb_df, res_dict, dataset_name):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18,6))\n",
    "\n",
    "    approach_order = ['baseline-MSL', 'baseline-MEE']\n",
    "    filter = filter_approaches(wandb_df, dataset=dataset_name, approaches=approach_order)\n",
    "    merged = merge_residuals_and_metadata(wandb_df, res_dict, filter=filter)\n",
    "    sns.histplot(data=merged, x='residuals', hue='approach', hue_order=approach_order, ax=axes[0])\n",
    "\n",
    "    approach_order = ['MSL-MSL', 'MSL-MEE']\n",
    "    filter = filter_approaches(wandb_df, dataset=dataset_name, approaches=approach_order)\n",
    "    merged = merge_residuals_and_metadata(wandb_df, res_dict, filter=filter)\n",
    "    sns.histplot(data=merged, x='residuals', hue='approach', hue_order=approach_order, ax=axes[1])\n",
    "\n",
    "    plt.savefig(f\"plots/{dataset_name}_histograms.png\", bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CMAPSS target dataset 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nasa_tar1_filter = residual_df['train_dataset'].str.contains('tar1')\n",
    "nasa_tar1_results = residual_df[nasa_tar1_filter]\n",
    "# wandb_data = wandb_data[wandb_data['tcn2'] == False]\n",
    "# wandb_data = wandb_data[wandb_data['State'] == 'finished']\n",
    "# nasa_tar1_results = nasa_tar1_results[~nasa_tar1_results['group'].str.contains('src')] # remove source network results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_boxplots(residual_df, \"tar1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# nasa_tar1_results.groupby('approach')['test/mse'].agg(['mean', 'std', 'median'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_histograms(residual_df, residuals, 'tar1')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "----------------------------------------------------------\n",
    "# CMAPSS target dataset 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot_boxplots(residual_df[residual_df['approach'] != 'baseline-MEE'], \"tar2\")\n",
    "plot_boxplots(residual_df, \"tar2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# nasa_tar2_results.groupby('approach')['test/mse'].agg(['mean', 'std', 'median'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_histograms(residual_df, residuals, 'tar2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "------------------\n",
    "## CMAPSS target dataset 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_boxplots(residual_df, \"tar3\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# nasa_tar3_results = residual_df[residual_df['train_dataset'].str.contains('tar3')]\n",
    "# nasa_tar3_results.groupby('approach')['test/mse'].agg(['mean', 'std', 'median'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_histograms(residual_df, residuals, 'tar3')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "------------------\n",
    "# BPM10 dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# bpm10_tar_results = residual_df[residual_df['train_dataset'].str.contains('bpm10')]\n",
    "# bpm10_tar_results.groupby('approach')['test/mse'].agg(['mean', 'std', 'median'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_boxplots(residual_df, \"bpm10_tar\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_histograms(residual_df, residuals, 'bpm10_tar')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----------------------------------\n",
    "# Bike rental 2011"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bike11_results = residual_df[residual_df['train_dataset'].str.contains('bike11_tar')]\n",
    "bike11_results.groupby('approach')['test/mse'].agg(['mean', 'std', 'median'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_boxplots(residual_df, \"bike11_tar\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_histograms(residual_df, residuals, 'bike11_tar')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "gijs_paper_env",
   "language": "python",
   "display_name": "gijs_paper_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
