{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Unable to patch Tensorflow/Keras\n",
      "exception while trying to patch_tf_keras\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gijst\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\", line 77, in patch_tf_keras\n",
      "    from keras.engine import training\n",
      "  File \"c:\\Users\\gijst\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\wandb\\util.py\", line 1344, in load_module\n",
      "    mod = importlib.import_module(fullname)\n",
      "  File \"c:\\Users\\gijst\\anaconda3\\envs\\tf-gpu\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "ModuleNotFoundError: No module named 'keras'\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgijstimmerij\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\gijst\\Documents\\Uni\\scriptie\\Transfer Learning\\wandb\\run-20220611_152422-11kmvkqo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gijstimmerij/transfer_learning/runs/11kmvkqo\" target=\"_blank\">wise-smoke-6</a></strong> to <a href=\"https://wandb.ai/gijstimmerij/transfer_learning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "run = wandb.init(project='transfer_learning', entity='gijstimmerij', reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import tensorflow as tf\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.machinery import SourceFileLoader\n",
    "somemodule = SourceFileLoader('tcn', r'C:\\Users\\gijst\\Documents\\Uni\\scriptie\\RUL-prediction\\keras-tcn-master\\tcn\\tcn.py').load_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'df3'\n",
    "swp_X = np.load(f'Data/{dataset}/swpX.npy')\n",
    "swp_y = np.load(f'Data/{dataset}/swpy.npy')\n",
    "swp_X_test = np.load(f'Data/{dataset}/swpX_test.npy')\n",
    "swp_y_test = np.load(f'Data/{dataset}/swpy_test.npy')\n",
    "swp_X_reduced = np.load(f'Data/{dataset}/swpX_reducedn10.npy')\n",
    "swp_y_reduced = np.load(f'Data/{dataset}/swpy_reducedn10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 16, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swp_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcn import TCN\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "model_path = r\"C:\\Users\\gijst\\Documents\\Uni\\scriptie\\Transfer Learning\\models\\swp_30_best\\df1_ft64_ks3_do06.h5\"\n",
    "estimator = load_model(model_path, custom_objects={\n",
    "                       'root_mean_squared_error': root_mean_squared_error, 'TCN': TCN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 16, 30)]          0         \n",
      "_________________________________________________________________\n",
      "tcn_76 (TCN)                 (None, 16, 64)            171008    \n",
      "_________________________________________________________________\n",
      "tcn_77 (TCN)                 (None, 32)                44608     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 215,649\n",
      "Trainable params: 215,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "estimator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set layers to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\gijst\\Documents\\Uni\\scriptie\\Transfer Learning\\wandb\\run-20220611_161446-2dypfmyd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gijstimmerij/transfer_learning1/runs/2dypfmyd\" target=\"_blank\">sage-forest-98</a></strong> to <a href=\"https://wandb.ai/gijstimmerij/transfer_learning1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 5/13 [==========>...................] - ETA: 0s - loss: 109.7683 - mae: 86.9476 - root_mean_squared_error: 109.7683WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0196s vs `on_train_batch_end` time: 0.0494s). Check your callbacks.\n",
      "13/13 [==============================] - 6s 109ms/step - loss: 98.9602 - mae: 78.2073 - root_mean_squared_error: 98.3987 - val_loss: 36.5299 - val_mae: 30.4188 - val_root_mean_squared_error: 36.5299\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 88.1895 - mae: 69.3635 - root_mean_squared_error: 88.3083 - val_loss: 26.6340 - val_mae: 20.6107 - val_root_mean_squared_error: 26.6340\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 85.7744 - mae: 68.1045 - root_mean_squared_error: 86.0743 - val_loss: 30.4559 - val_mae: 24.6217 - val_root_mean_squared_error: 30.4559\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 82.4651 - mae: 66.0927 - root_mean_squared_error: 81.9827 - val_loss: 32.4321 - val_mae: 26.5179 - val_root_mean_squared_error: 32.4321\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 81.2409 - mae: 64.9561 - root_mean_squared_error: 82.1554 - val_loss: 30.5572 - val_mae: 24.7183 - val_root_mean_squared_error: 30.5572\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 82.7545 - mae: 65.5119 - root_mean_squared_error: 82.7288 - val_loss: 31.4292 - val_mae: 25.7619 - val_root_mean_squared_error: 31.4292\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 78.7909 - mae: 62.9957 - root_mean_squared_error: 78.1992 - val_loss: 34.0470 - val_mae: 28.7375 - val_root_mean_squared_error: 34.0470\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 78.0904 - mae: 62.2635 - root_mean_squared_error: 79.2299 - val_loss: 32.5830 - val_mae: 27.2146 - val_root_mean_squared_error: 32.5830\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 78.7498 - mae: 62.9250 - root_mean_squared_error: 79.2674 - val_loss: 34.3448 - val_mae: 29.0977 - val_root_mean_squared_error: 34.3448\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 80.9112 - mae: 65.2133 - root_mean_squared_error: 79.5718 - val_loss: 35.1606 - val_mae: 29.8227 - val_root_mean_squared_error: 35.1606\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 78.0556 - mae: 63.1425 - root_mean_squared_error: 78.0387 - val_loss: 35.4233 - val_mae: 30.1108 - val_root_mean_squared_error: 35.4233\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 76.8406 - mae: 61.7819 - root_mean_squared_error: 76.4345 - val_loss: 36.8979 - val_mae: 31.7200 - val_root_mean_squared_error: 36.8979\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 77.0931 - mae: 61.9379 - root_mean_squared_error: 75.9861 - val_loss: 35.8614 - val_mae: 30.6080 - val_root_mean_squared_error: 35.8614\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 76.2361 - mae: 61.3329 - root_mean_squared_error: 75.6834 - val_loss: 36.3934 - val_mae: 31.1242 - val_root_mean_squared_error: 36.3934\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 76.6943 - mae: 61.9641 - root_mean_squared_error: 76.8683 - val_loss: 36.5134 - val_mae: 31.2391 - val_root_mean_squared_error: 36.5134\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 74.4220 - mae: 59.8331 - root_mean_squared_error: 74.2378 - val_loss: 37.6955 - val_mae: 32.5434 - val_root_mean_squared_error: 37.6955\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 76.3972 - mae: 61.4585 - root_mean_squared_error: 75.9939 - val_loss: 37.7502 - val_mae: 32.6120 - val_root_mean_squared_error: 37.7502\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.8422 - mae: 60.6241 - root_mean_squared_error: 75.4846 - val_loss: 37.9590 - val_mae: 32.8207 - val_root_mean_squared_error: 37.9590\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 76.3025 - mae: 61.6336 - root_mean_squared_error: 76.5220 - val_loss: 37.2373 - val_mae: 32.0196 - val_root_mean_squared_error: 37.2373\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 76.7668 - mae: 61.6916 - root_mean_squared_error: 76.7238 - val_loss: 37.0072 - val_mae: 31.7593 - val_root_mean_squared_error: 37.0072\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 75.5227 - mae: 60.9309 - root_mean_squared_error: 75.0930 - val_loss: 37.9797 - val_mae: 32.8499 - val_root_mean_squared_error: 37.9797\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.9898 - mae: 61.3002 - root_mean_squared_error: 76.2946 - val_loss: 38.0583 - val_mae: 32.9525 - val_root_mean_squared_error: 38.0583\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.5436 - mae: 60.6251 - root_mean_squared_error: 75.7650 - val_loss: 37.5747 - val_mae: 32.4383 - val_root_mean_squared_error: 37.5747\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 77.0977 - mae: 61.6456 - root_mean_squared_error: 76.8829 - val_loss: 37.2354 - val_mae: 32.0786 - val_root_mean_squared_error: 37.2354\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.1246 - mae: 60.2130 - root_mean_squared_error: 75.2504 - val_loss: 37.5162 - val_mae: 32.3816 - val_root_mean_squared_error: 37.5162\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 76.8569 - mae: 62.3031 - root_mean_squared_error: 76.0232 - val_loss: 37.8353 - val_mae: 32.7134 - val_root_mean_squared_error: 37.8353\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 76.2560 - mae: 61.1980 - root_mean_squared_error: 76.4967 - val_loss: 37.9345 - val_mae: 32.8173 - val_root_mean_squared_error: 37.9345\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.1776 - mae: 60.3288 - root_mean_squared_error: 76.0675 - val_loss: 37.8524 - val_mae: 32.7142 - val_root_mean_squared_error: 37.8524\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.4319 - mae: 60.8447 - root_mean_squared_error: 75.6824 - val_loss: 37.7895 - val_mae: 32.6365 - val_root_mean_squared_error: 37.7895\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.6189 - mae: 60.6380 - root_mean_squared_error: 75.6690 - val_loss: 37.7898 - val_mae: 32.6306 - val_root_mean_squared_error: 37.7898\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 74.8581 - mae: 60.1312 - root_mean_squared_error: 73.5313 - val_loss: 37.8073 - val_mae: 32.6377 - val_root_mean_squared_error: 37.8073\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 74.2558 - mae: 59.6485 - root_mean_squared_error: 73.3927 - val_loss: 37.8739 - val_mae: 32.7109 - val_root_mean_squared_error: 37.8739\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.6465 - mae: 60.8475 - root_mean_squared_error: 76.2146 - val_loss: 37.7788 - val_mae: 32.6063 - val_root_mean_squared_error: 37.7788\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.0482 - mae: 60.9044 - root_mean_squared_error: 75.1158 - val_loss: 37.7639 - val_mae: 32.5894 - val_root_mean_squared_error: 37.7639\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.4736 - mae: 60.9097 - root_mean_squared_error: 76.1723 - val_loss: 37.8422 - val_mae: 32.6748 - val_root_mean_squared_error: 37.8422\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.7958 - mae: 61.2496 - root_mean_squared_error: 75.3819 - val_loss: 37.9495 - val_mae: 32.7880 - val_root_mean_squared_error: 37.9495\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.2285 - mae: 60.8500 - root_mean_squared_error: 75.0722 - val_loss: 37.9501 - val_mae: 32.7887 - val_root_mean_squared_error: 37.9501\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 76.2037 - mae: 61.1791 - root_mean_squared_error: 76.3416 - val_loss: 37.9455 - val_mae: 32.7849 - val_root_mean_squared_error: 37.9455\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.0549 - mae: 60.5560 - root_mean_squared_error: 76.0116 - val_loss: 37.9670 - val_mae: 32.8089 - val_root_mean_squared_error: 37.9670\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 74.1849 - mae: 59.5355 - root_mean_squared_error: 73.6300 - val_loss: 37.9545 - val_mae: 32.7948 - val_root_mean_squared_error: 37.9545\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.0229 - mae: 60.4082 - root_mean_squared_error: 74.9106 - val_loss: 37.9663 - val_mae: 32.8094 - val_root_mean_squared_error: 37.9663\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 74.1317 - mae: 59.6347 - root_mean_squared_error: 74.2676 - val_loss: 37.9843 - val_mae: 32.8286 - val_root_mean_squared_error: 37.9843\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.7461 - mae: 61.1379 - root_mean_squared_error: 76.3069 - val_loss: 37.9945 - val_mae: 32.8394 - val_root_mean_squared_error: 37.9945\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 73.9965 - mae: 59.5650 - root_mean_squared_error: 73.8721 - val_loss: 38.0149 - val_mae: 32.8621 - val_root_mean_squared_error: 38.0149\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 73.8139 - mae: 59.4650 - root_mean_squared_error: 73.8440 - val_loss: 38.0312 - val_mae: 32.8801 - val_root_mean_squared_error: 38.0312\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 75.3991 - mae: 61.1223 - root_mean_squared_error: 75.7655 - val_loss: 38.0384 - val_mae: 32.8889 - val_root_mean_squared_error: 38.0384\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.5552 - mae: 60.3625 - root_mean_squared_error: 75.4721 - val_loss: 38.0373 - val_mae: 32.8880 - val_root_mean_squared_error: 38.0373\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 75.1160 - mae: 60.4847 - root_mean_squared_error: 75.5356 - val_loss: 38.0321 - val_mae: 32.8828 - val_root_mean_squared_error: 38.0321\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 74.4612 - mae: 59.8941 - root_mean_squared_error: 74.6218 - val_loss: 38.0257 - val_mae: 32.8754 - val_root_mean_squared_error: 38.0257\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 73.4081 - mae: 59.4263 - root_mean_squared_error: 73.6323 - val_loss: 38.0210 - val_mae: 32.8698 - val_root_mean_squared_error: 38.0210\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.1814 - mae: 60.6271 - root_mean_squared_error: 75.0935 - val_loss: 38.0240 - val_mae: 32.8730 - val_root_mean_squared_error: 38.0240\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 74.3859 - mae: 60.1478 - root_mean_squared_error: 73.6379 - val_loss: 38.0288 - val_mae: 32.8784 - val_root_mean_squared_error: 38.0288\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.0088 - mae: 60.5568 - root_mean_squared_error: 74.0131 - val_loss: 38.0310 - val_mae: 32.8810 - val_root_mean_squared_error: 38.0310\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 74.5667 - mae: 59.7182 - root_mean_squared_error: 73.8578 - val_loss: 38.0358 - val_mae: 32.8861 - val_root_mean_squared_error: 38.0358\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 76.9546 - mae: 61.0639 - root_mean_squared_error: 76.7943 - val_loss: 38.0369 - val_mae: 32.8871 - val_root_mean_squared_error: 38.0369\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.6982 - mae: 60.7231 - root_mean_squared_error: 75.1688 - val_loss: 38.0368 - val_mae: 32.8865 - val_root_mean_squared_error: 38.0368\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 76.2793 - mae: 61.0516 - root_mean_squared_error: 76.7365 - val_loss: 38.0328 - val_mae: 32.8821 - val_root_mean_squared_error: 38.0328\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 76.4919 - mae: 61.3156 - root_mean_squared_error: 76.0721 - val_loss: 38.0307 - val_mae: 32.8797 - val_root_mean_squared_error: 38.0307\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 74.5227 - mae: 59.5152 - root_mean_squared_error: 74.7273 - val_loss: 38.0327 - val_mae: 32.8818 - val_root_mean_squared_error: 38.0327\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.2002 - mae: 60.6979 - root_mean_squared_error: 74.5876 - val_loss: 38.0336 - val_mae: 32.8828 - val_root_mean_squared_error: 38.0336\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 73.8870 - mae: 59.9294 - root_mean_squared_error: 73.2852 - val_loss: 38.0360 - val_mae: 32.8854 - val_root_mean_squared_error: 38.0360\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 77.1011 - mae: 61.9999 - root_mean_squared_error: 76.9317 - val_loss: 38.0363 - val_mae: 32.8859 - val_root_mean_squared_error: 38.0363\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 75.1285 - mae: 60.5649 - root_mean_squared_error: 75.3821 - val_loss: 38.0371 - val_mae: 32.8867 - val_root_mean_squared_error: 38.0371\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 76.0003 - mae: 61.1738 - root_mean_squared_error: 74.5943 - val_loss: 38.0385 - val_mae: 32.8883 - val_root_mean_squared_error: 38.0385\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 74.8997 - mae: 60.4105 - root_mean_squared_error: 74.5249 - val_loss: 38.0383 - val_mae: 32.8880 - val_root_mean_squared_error: 38.0383\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.1422 - mae: 60.2427 - root_mean_squared_error: 74.5289 - val_loss: 38.0389 - val_mae: 32.8887 - val_root_mean_squared_error: 38.0389\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 76.0362 - mae: 61.3988 - root_mean_squared_error: 75.8491 - val_loss: 38.0380 - val_mae: 32.8876 - val_root_mean_squared_error: 38.0380\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 76.4086 - mae: 61.1525 - root_mean_squared_error: 77.3607 - val_loss: 38.0383 - val_mae: 32.8879 - val_root_mean_squared_error: 38.0383\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.3477 - mae: 60.4066 - root_mean_squared_error: 75.4244 - val_loss: 38.0382 - val_mae: 32.8879 - val_root_mean_squared_error: 38.0382\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 73.9848 - mae: 59.5335 - root_mean_squared_error: 73.3514 - val_loss: 38.0391 - val_mae: 32.8888 - val_root_mean_squared_error: 38.0391\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.4557 - mae: 60.4562 - root_mean_squared_error: 75.6141 - val_loss: 38.0400 - val_mae: 32.8898 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.5076 - mae: 60.7216 - root_mean_squared_error: 75.2482 - val_loss: 38.0407 - val_mae: 32.8906 - val_root_mean_squared_error: 38.0407\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 74.3515 - mae: 59.1726 - root_mean_squared_error: 74.0067 - val_loss: 38.0409 - val_mae: 32.8908 - val_root_mean_squared_error: 38.0409\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 75.5712 - mae: 60.8761 - root_mean_squared_error: 75.0906 - val_loss: 38.0405 - val_mae: 32.8904 - val_root_mean_squared_error: 38.0405\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 75.6623 - mae: 60.7944 - root_mean_squared_error: 76.2813 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 73.9999 - mae: 59.6226 - root_mean_squared_error: 74.7910 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.6650 - mae: 60.3288 - root_mean_squared_error: 75.9036 - val_loss: 38.0396 - val_mae: 32.8894 - val_root_mean_squared_error: 38.0396\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 74.0746 - mae: 59.4145 - root_mean_squared_error: 73.2641 - val_loss: 38.0395 - val_mae: 32.8893 - val_root_mean_squared_error: 38.0395\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.7751 - mae: 61.0484 - root_mean_squared_error: 76.1679 - val_loss: 38.0397 - val_mae: 32.8895 - val_root_mean_squared_error: 38.0397\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 73.5293 - mae: 58.8803 - root_mean_squared_error: 74.5741 - val_loss: 38.0398 - val_mae: 32.8897 - val_root_mean_squared_error: 38.0398\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 75.8798 - mae: 60.6256 - root_mean_squared_error: 75.8843 - val_loss: 38.0400 - val_mae: 32.8898 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 74.8865 - mae: 59.9425 - root_mean_squared_error: 74.8612 - val_loss: 38.0401 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0401\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 76.1537 - mae: 60.9616 - root_mean_squared_error: 75.9098 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 74.9396 - mae: 60.7552 - root_mean_squared_error: 75.9468 - val_loss: 38.0401 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0401\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 74.6389 - mae: 60.7075 - root_mean_squared_error: 74.9264 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.0505 - mae: 60.5907 - root_mean_squared_error: 74.2948 - val_loss: 38.0401 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0401\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 76.7924 - mae: 61.6137 - root_mean_squared_error: 77.8054 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.5066 - mae: 60.8855 - root_mean_squared_error: 75.9961 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 76.3869 - mae: 61.6168 - root_mean_squared_error: 76.9642 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 73.9716 - mae: 59.5018 - root_mean_squared_error: 73.6074 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 75.4932 - mae: 60.5676 - root_mean_squared_error: 74.9547 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 73.8493 - mae: 59.7593 - root_mean_squared_error: 73.2993 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 74.5771 - mae: 60.4480 - root_mean_squared_error: 75.1010 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 76.2824 - mae: 61.2955 - root_mean_squared_error: 75.2458 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 75.3895 - mae: 60.8386 - root_mean_squared_error: 76.2850 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 74.7325 - mae: 60.0627 - root_mean_squared_error: 74.6691 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 74.6853 - mae: 60.5235 - root_mean_squared_error: 74.1518 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 74.8624 - mae: 60.0792 - root_mean_squared_error: 75.0498 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 75.4409 - mae: 60.7450 - root_mean_squared_error: 75.0979 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 74.9123 - mae: 60.4183 - root_mean_squared_error: 75.1818 - val_loss: 38.0400 - val_mae: 32.8899 - val_root_mean_squared_error: 38.0400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d610008ea5241b48901e0614dda9ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.709 MB of 2.709 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▁▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁▂▁▁▂▂▁▁▁▂▂▁▁▂▂▁▂▁▁</td></tr><tr><td>mae</td><td>█▄▃▂▂▂▁▁▂▁▂▁▁▂▂▁▁▁▂▁▁▁▁▁▁▂▂▁▁▂▁▂▁▁▂▂▁▂▁▁</td></tr><tr><td>root_mean_squared_error</td><td>█▅▄▃▂▂▁▂▂▂▂▂▁▂▂▂▁▁▂▁▂▁▂▁▁▁▂▂▂▂▂▂▁▂▂▂▁▂▁▂</td></tr><tr><td>val_loss</td><td>▇▁▂▃▆▆██████████████████████████████████</td></tr><tr><td>val_mae</td><td>▆▁▂▃▆▆██████████████████████████████████</td></tr><tr><td>val_root_mean_squared_error</td><td>▇▁▂▃▆▆██████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>26.63396</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>74.9123</td></tr><tr><td>mae</td><td>60.41826</td></tr><tr><td>root_mean_squared_error</td><td>75.18178</td></tr><tr><td>val_loss</td><td>38.04004</td></tr><tr><td>val_mae</td><td>32.88988</td></tr><tr><td>val_root_mean_squared_error</td><td>38.04004</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sage-forest-98</strong>: <a href=\"https://wandb.ai/gijstimmerij/transfer_learning1/runs/2dypfmyd\" target=\"_blank\">https://wandb.ai/gijstimmerij/transfer_learning1/runs/2dypfmyd</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220611_161446-2dypfmyd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\gijst\\Documents\\Uni\\scriptie\\Transfer Learning\\wandb\\run-20220611_161543-3cnvexzo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gijstimmerij/transfer_learning1/runs/3cnvexzo\" target=\"_blank\">feasible-dew-99</a></strong> to <a href=\"https://wandb.ai/gijstimmerij/transfer_learning1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 5/13 [==========>...................] - ETA: 0s - loss: 270.4558 - mae: 243.3039 - root_mean_squared_error: 270.4558WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0251s vs `on_train_batch_end` time: 0.0511s). Check your callbacks.\n",
      "13/13 [==============================] - 6s 109ms/step - loss: 274.9442 - mae: 248.9967 - root_mean_squared_error: 273.9099 - val_loss: 166.1506 - val_mae: 156.2057 - val_root_mean_squared_error: 166.1506\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 275.0706 - mae: 249.3940 - root_mean_squared_error: 273.7471 - val_loss: 166.1504 - val_mae: 156.2055 - val_root_mean_squared_error: 166.1504\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 275.9303 - mae: 250.0389 - root_mean_squared_error: 276.1931 - val_loss: 166.1502 - val_mae: 156.2053 - val_root_mean_squared_error: 166.1502\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 274.7255 - mae: 248.7886 - root_mean_squared_error: 273.5388 - val_loss: 166.1501 - val_mae: 156.2051 - val_root_mean_squared_error: 166.1501\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 273.9896 - mae: 248.4665 - root_mean_squared_error: 272.5484 - val_loss: 166.1499 - val_mae: 156.2050 - val_root_mean_squared_error: 166.1499\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 275.3287 - mae: 248.8945 - root_mean_squared_error: 275.0014 - val_loss: 166.1498 - val_mae: 156.2049 - val_root_mean_squared_error: 166.1498\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.4090 - mae: 249.3446 - root_mean_squared_error: 275.4479 - val_loss: 166.1497 - val_mae: 156.2048 - val_root_mean_squared_error: 166.1497\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 272.7383 - mae: 247.2155 - root_mean_squared_error: 270.6975 - val_loss: 166.1496 - val_mae: 156.2046 - val_root_mean_squared_error: 166.1496\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 274.5208 - mae: 248.2619 - root_mean_squared_error: 274.1323 - val_loss: 166.1494 - val_mae: 156.2045 - val_root_mean_squared_error: 166.1494\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 272.9533 - mae: 247.7316 - root_mean_squared_error: 273.8723 - val_loss: 166.1493 - val_mae: 156.2044 - val_root_mean_squared_error: 166.1493\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.0135 - mae: 248.7619 - root_mean_squared_error: 275.0330 - val_loss: 166.1492 - val_mae: 156.2043 - val_root_mean_squared_error: 166.1492\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 274.0598 - mae: 248.0460 - root_mean_squared_error: 271.8390 - val_loss: 166.1491 - val_mae: 156.2042 - val_root_mean_squared_error: 166.1491\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 275.7704 - mae: 249.7777 - root_mean_squared_error: 275.8742 - val_loss: 166.1491 - val_mae: 156.2042 - val_root_mean_squared_error: 166.1491\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 277.1186 - mae: 250.5780 - root_mean_squared_error: 276.3224 - val_loss: 166.1490 - val_mae: 156.2041 - val_root_mean_squared_error: 166.1490\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 272.2585 - mae: 246.7389 - root_mean_squared_error: 273.7182 - val_loss: 166.1489 - val_mae: 156.2040 - val_root_mean_squared_error: 166.1489\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 277.7094 - mae: 251.3917 - root_mean_squared_error: 278.1881 - val_loss: 166.1488 - val_mae: 156.2039 - val_root_mean_squared_error: 166.1488\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.1783 - mae: 248.9567 - root_mean_squared_error: 273.2372 - val_loss: 166.1487 - val_mae: 156.2039 - val_root_mean_squared_error: 166.1487\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 272.5140 - mae: 246.4323 - root_mean_squared_error: 273.7550 - val_loss: 166.1487 - val_mae: 156.2038 - val_root_mean_squared_error: 166.1487\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.5969 - mae: 250.1803 - root_mean_squared_error: 275.7138 - val_loss: 166.1486 - val_mae: 156.2038 - val_root_mean_squared_error: 166.1486\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 274.5259 - mae: 248.7167 - root_mean_squared_error: 275.9296 - val_loss: 166.1486 - val_mae: 156.2037 - val_root_mean_squared_error: 166.1486\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 276.9228 - mae: 250.4424 - root_mean_squared_error: 278.4641 - val_loss: 166.1485 - val_mae: 156.2037 - val_root_mean_squared_error: 166.1485\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 274.8135 - mae: 249.0869 - root_mean_squared_error: 272.2697 - val_loss: 166.1485 - val_mae: 156.2036 - val_root_mean_squared_error: 166.1485\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.0046 - mae: 249.2694 - root_mean_squared_error: 276.1690 - val_loss: 166.1484 - val_mae: 156.2035 - val_root_mean_squared_error: 166.1484\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 275.7927 - mae: 249.9039 - root_mean_squared_error: 273.8472 - val_loss: 166.1484 - val_mae: 156.2035 - val_root_mean_squared_error: 166.1484\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.7660 - mae: 249.3194 - root_mean_squared_error: 274.2107 - val_loss: 166.1483 - val_mae: 156.2034 - val_root_mean_squared_error: 166.1483\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 275.9756 - mae: 250.1426 - root_mean_squared_error: 276.7510 - val_loss: 166.1483 - val_mae: 156.2034 - val_root_mean_squared_error: 166.1483\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 274.2134 - mae: 248.1265 - root_mean_squared_error: 275.1304 - val_loss: 166.1482 - val_mae: 156.2033 - val_root_mean_squared_error: 166.1482\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.0937 - mae: 248.8079 - root_mean_squared_error: 273.9549 - val_loss: 166.1482 - val_mae: 156.2033 - val_root_mean_squared_error: 166.1482\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 273.7718 - mae: 248.3100 - root_mean_squared_error: 270.9322 - val_loss: 166.1481 - val_mae: 156.2032 - val_root_mean_squared_error: 166.1481\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 272.3208 - mae: 246.4436 - root_mean_squared_error: 271.6195 - val_loss: 166.1481 - val_mae: 156.2032 - val_root_mean_squared_error: 166.1481\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 273.8298 - mae: 247.9647 - root_mean_squared_error: 273.6419 - val_loss: 166.1480 - val_mae: 156.2032 - val_root_mean_squared_error: 166.1480\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 273.6951 - mae: 247.9273 - root_mean_squared_error: 270.9990 - val_loss: 166.1480 - val_mae: 156.2031 - val_root_mean_squared_error: 166.1480\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 274.2206 - mae: 248.7392 - root_mean_squared_error: 275.2558 - val_loss: 166.1479 - val_mae: 156.2031 - val_root_mean_squared_error: 166.1479\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 275.6037 - mae: 249.3289 - root_mean_squared_error: 274.9100 - val_loss: 166.1479 - val_mae: 156.2030 - val_root_mean_squared_error: 166.1479\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 277.8098 - mae: 250.2518 - root_mean_squared_error: 278.2604 - val_loss: 166.1478 - val_mae: 156.2029 - val_root_mean_squared_error: 166.1478\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 273.1609 - mae: 247.1009 - root_mean_squared_error: 275.8605 - val_loss: 166.1478 - val_mae: 156.2029 - val_root_mean_squared_error: 166.1478\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 275.0827 - mae: 249.6206 - root_mean_squared_error: 273.6118 - val_loss: 166.1477 - val_mae: 156.2029 - val_root_mean_squared_error: 166.1477\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.2170 - mae: 249.2183 - root_mean_squared_error: 275.3738 - val_loss: 166.1477 - val_mae: 156.2028 - val_root_mean_squared_error: 166.1477\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 277.7274 - mae: 251.1356 - root_mean_squared_error: 277.0983 - val_loss: 166.1476 - val_mae: 156.2028 - val_root_mean_squared_error: 166.1476\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.0733 - mae: 248.8566 - root_mean_squared_error: 274.5254 - val_loss: 166.1476 - val_mae: 156.2027 - val_root_mean_squared_error: 166.1476\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 275.0936 - mae: 249.5557 - root_mean_squared_error: 275.5732 - val_loss: 166.1475 - val_mae: 156.2027 - val_root_mean_squared_error: 166.1475\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 277.0183 - mae: 250.6618 - root_mean_squared_error: 278.4189 - val_loss: 166.1475 - val_mae: 156.2026 - val_root_mean_squared_error: 166.1475\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 274.3303 - mae: 248.9156 - root_mean_squared_error: 275.3477 - val_loss: 166.1474 - val_mae: 156.2026 - val_root_mean_squared_error: 166.1474\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 273.9077 - mae: 248.2995 - root_mean_squared_error: 275.3465 - val_loss: 166.1474 - val_mae: 156.2026 - val_root_mean_squared_error: 166.1474\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 273.5500 - mae: 248.0516 - root_mean_squared_error: 275.3625 - val_loss: 166.1474 - val_mae: 156.2025 - val_root_mean_squared_error: 166.1474\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.1579 - mae: 248.8398 - root_mean_squared_error: 274.6363 - val_loss: 166.1473 - val_mae: 156.2025 - val_root_mean_squared_error: 166.1473\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 275.1472 - mae: 248.4532 - root_mean_squared_error: 275.4663 - val_loss: 166.1473 - val_mae: 156.2024 - val_root_mean_squared_error: 166.1473\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 273.8612 - mae: 248.4303 - root_mean_squared_error: 273.7335 - val_loss: 166.1472 - val_mae: 156.2024 - val_root_mean_squared_error: 166.1472\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 272.8471 - mae: 247.8785 - root_mean_squared_error: 271.6026 - val_loss: 166.1472 - val_mae: 156.2023 - val_root_mean_squared_error: 166.1472\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 276.3548 - mae: 250.2630 - root_mean_squared_error: 275.7333 - val_loss: 166.1471 - val_mae: 156.2023 - val_root_mean_squared_error: 166.1471\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 274.0551 - mae: 247.9456 - root_mean_squared_error: 272.1719 - val_loss: 166.1471 - val_mae: 156.2023 - val_root_mean_squared_error: 166.1471\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 276.4494 - mae: 249.9200 - root_mean_squared_error: 275.2041 - val_loss: 166.1470 - val_mae: 156.2022 - val_root_mean_squared_error: 166.1470\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.6375 - mae: 248.6954 - root_mean_squared_error: 274.2093 - val_loss: 166.1470 - val_mae: 156.2021 - val_root_mean_squared_error: 166.1470\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 274.0872 - mae: 248.2861 - root_mean_squared_error: 273.8037 - val_loss: 166.1470 - val_mae: 156.2021 - val_root_mean_squared_error: 166.1470\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 273.1451 - mae: 247.8086 - root_mean_squared_error: 271.8683 - val_loss: 166.1469 - val_mae: 156.2021 - val_root_mean_squared_error: 166.1469\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 275.2477 - mae: 249.0246 - root_mean_squared_error: 275.9607 - val_loss: 166.1469 - val_mae: 156.2020 - val_root_mean_squared_error: 166.1469\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 277.0002 - mae: 250.6947 - root_mean_squared_error: 276.5629 - val_loss: 166.1468 - val_mae: 156.2020 - val_root_mean_squared_error: 166.1468\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.8961 - mae: 249.0421 - root_mean_squared_error: 275.5055 - val_loss: 166.1468 - val_mae: 156.2020 - val_root_mean_squared_error: 166.1468\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 272.7136 - mae: 248.0432 - root_mean_squared_error: 271.2456 - val_loss: 166.1467 - val_mae: 156.2019 - val_root_mean_squared_error: 166.1467\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.4108 - mae: 248.1821 - root_mean_squared_error: 273.3739 - val_loss: 166.1467 - val_mae: 156.2019 - val_root_mean_squared_error: 166.1467\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 273.5404 - mae: 247.8509 - root_mean_squared_error: 274.1595 - val_loss: 166.1467 - val_mae: 156.2018 - val_root_mean_squared_error: 166.1467\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.6048 - mae: 248.7703 - root_mean_squared_error: 276.1404 - val_loss: 166.1466 - val_mae: 156.2018 - val_root_mean_squared_error: 166.1466\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 274.3894 - mae: 248.3429 - root_mean_squared_error: 275.3139 - val_loss: 166.1466 - val_mae: 156.2018 - val_root_mean_squared_error: 166.1466\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 273.5360 - mae: 247.3607 - root_mean_squared_error: 275.0846 - val_loss: 166.1465 - val_mae: 156.2017 - val_root_mean_squared_error: 166.1465\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 273.9200 - mae: 247.6876 - root_mean_squared_error: 274.8923 - val_loss: 166.1465 - val_mae: 156.2017 - val_root_mean_squared_error: 166.1465\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 274.8681 - mae: 248.4215 - root_mean_squared_error: 275.7335 - val_loss: 166.1464 - val_mae: 156.2016 - val_root_mean_squared_error: 166.1464\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 275.0633 - mae: 249.0811 - root_mean_squared_error: 274.6503 - val_loss: 166.1464 - val_mae: 156.2016 - val_root_mean_squared_error: 166.1464\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 276.3853 - mae: 250.6543 - root_mean_squared_error: 275.3829 - val_loss: 166.1463 - val_mae: 156.2016 - val_root_mean_squared_error: 166.1463\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 276.9762 - mae: 250.5265 - root_mean_squared_error: 276.4083 - val_loss: 166.1463 - val_mae: 156.2015 - val_root_mean_squared_error: 166.1463\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.3172 - mae: 248.2844 - root_mean_squared_error: 274.7188 - val_loss: 166.1463 - val_mae: 156.2015 - val_root_mean_squared_error: 166.1463\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.4796 - mae: 248.3229 - root_mean_squared_error: 275.5701 - val_loss: 166.1462 - val_mae: 156.2014 - val_root_mean_squared_error: 166.1462\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 275.3284 - mae: 249.3654 - root_mean_squared_error: 274.3970 - val_loss: 166.1462 - val_mae: 156.2014 - val_root_mean_squared_error: 166.1462\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.8796 - mae: 249.1440 - root_mean_squared_error: 275.0139 - val_loss: 166.1461 - val_mae: 156.2013 - val_root_mean_squared_error: 166.1461\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 273.1979 - mae: 247.1203 - root_mean_squared_error: 273.4643 - val_loss: 166.1461 - val_mae: 156.2013 - val_root_mean_squared_error: 166.1461\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 274.4809 - mae: 249.1986 - root_mean_squared_error: 273.5836 - val_loss: 166.1461 - val_mae: 156.2013 - val_root_mean_squared_error: 166.1461\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 277.0348 - mae: 250.4761 - root_mean_squared_error: 275.5620 - val_loss: 166.1460 - val_mae: 156.2012 - val_root_mean_squared_error: 166.1460\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 275.7467 - mae: 249.2360 - root_mean_squared_error: 273.9142 - val_loss: 166.1460 - val_mae: 156.2012 - val_root_mean_squared_error: 166.1460\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 275.2691 - mae: 249.0186 - root_mean_squared_error: 273.6992 - val_loss: 166.1459 - val_mae: 156.2011 - val_root_mean_squared_error: 166.1459\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 277.1523 - mae: 251.0547 - root_mean_squared_error: 275.1847 - val_loss: 166.1459 - val_mae: 156.2011 - val_root_mean_squared_error: 166.1459\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 273.2283 - mae: 247.5654 - root_mean_squared_error: 274.8750 - val_loss: 166.1458 - val_mae: 156.2011 - val_root_mean_squared_error: 166.1458\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 273.9953 - mae: 248.4955 - root_mean_squared_error: 273.1201 - val_loss: 166.1458 - val_mae: 156.2010 - val_root_mean_squared_error: 166.1458\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.7068 - mae: 248.9687 - root_mean_squared_error: 273.8790 - val_loss: 166.1458 - val_mae: 156.2010 - val_root_mean_squared_error: 166.1458\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.2727 - mae: 248.4555 - root_mean_squared_error: 274.6899 - val_loss: 166.1457 - val_mae: 156.2010 - val_root_mean_squared_error: 166.1457\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 276.8177 - mae: 250.7271 - root_mean_squared_error: 276.4110 - val_loss: 166.1457 - val_mae: 156.2009 - val_root_mean_squared_error: 166.1457\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 276.7875 - mae: 250.4853 - root_mean_squared_error: 275.5290 - val_loss: 166.1456 - val_mae: 156.2009 - val_root_mean_squared_error: 166.1456\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.4683 - mae: 248.3527 - root_mean_squared_error: 274.4048 - val_loss: 166.1456 - val_mae: 156.2008 - val_root_mean_squared_error: 166.1456\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.8735 - mae: 248.9507 - root_mean_squared_error: 274.3422 - val_loss: 166.1456 - val_mae: 156.2008 - val_root_mean_squared_error: 166.1456\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 276.4738 - mae: 250.0466 - root_mean_squared_error: 276.2007 - val_loss: 166.1455 - val_mae: 156.2007 - val_root_mean_squared_error: 166.1455\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.2467 - mae: 248.7941 - root_mean_squared_error: 274.1502 - val_loss: 166.1455 - val_mae: 156.2007 - val_root_mean_squared_error: 166.1455\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.6077 - mae: 249.3623 - root_mean_squared_error: 277.6126 - val_loss: 166.1455 - val_mae: 156.2007 - val_root_mean_squared_error: 166.1455\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 272.3661 - mae: 247.1187 - root_mean_squared_error: 272.2165 - val_loss: 166.1454 - val_mae: 156.2006 - val_root_mean_squared_error: 166.1454\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.0254 - mae: 249.6858 - root_mean_squared_error: 275.5446 - val_loss: 166.1454 - val_mae: 156.2006 - val_root_mean_squared_error: 166.1454\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 277.4866 - mae: 250.8748 - root_mean_squared_error: 276.8332 - val_loss: 166.1453 - val_mae: 156.2005 - val_root_mean_squared_error: 166.1453\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.0807 - mae: 248.2402 - root_mean_squared_error: 272.5628 - val_loss: 166.1453 - val_mae: 156.2005 - val_root_mean_squared_error: 166.1453\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 274.0368 - mae: 248.1402 - root_mean_squared_error: 272.9314 - val_loss: 166.1453 - val_mae: 156.2005 - val_root_mean_squared_error: 166.1453\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 272.3855 - mae: 246.8113 - root_mean_squared_error: 271.1501 - val_loss: 166.1452 - val_mae: 156.2004 - val_root_mean_squared_error: 166.1452\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 277.6675 - mae: 250.8378 - root_mean_squared_error: 279.6189 - val_loss: 166.1452 - val_mae: 156.2004 - val_root_mean_squared_error: 166.1452\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 277.9173 - mae: 250.7092 - root_mean_squared_error: 277.3744 - val_loss: 166.1451 - val_mae: 156.2004 - val_root_mean_squared_error: 166.1451\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 277.6251 - mae: 251.0078 - root_mean_squared_error: 277.1810 - val_loss: 166.1451 - val_mae: 156.2003 - val_root_mean_squared_error: 166.1451\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 275.5157 - mae: 248.8807 - root_mean_squared_error: 273.7970 - val_loss: 166.1451 - val_mae: 156.2003 - val_root_mean_squared_error: 166.1451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430c880ad35d4d9a9b8bed4905086230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.713 MB of 2.713 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▄▆▅▁▄▅█▁▇▄▆▄▃▅▂█▄▃▃▁▃▃▅▁▂▂▄▇▅▂▅▇▄▇▄▅▄▃█▅</td></tr><tr><td>mae</td><td>▅▆▄▂▄▆█▁▇▅▆▄▃▅▂█▅▄▄▃▃▄▅▃▃▂▅▇▅▂▅█▅▇▅▄▆▄▇▄</td></tr><tr><td>root_mean_squared_error</td><td>▄▅▄▁▄▅▇▃▇▅▆▄▃▄▅▆▅▅▄▂▂▃▅▁▄▄▄▅▄▃▄▅▃▅▄▄▅▂█▃</td></tr><tr><td>val_loss</td><td>██▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_mae</td><td>██▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_root_mean_squared_error</td><td>██▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>166.14507</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>275.51566</td></tr><tr><td>mae</td><td>248.88072</td></tr><tr><td>root_mean_squared_error</td><td>273.79697</td></tr><tr><td>val_loss</td><td>166.14507</td></tr><tr><td>val_mae</td><td>156.20029</td></tr><tr><td>val_root_mean_squared_error</td><td>166.14507</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">feasible-dew-99</strong>: <a href=\"https://wandb.ai/gijstimmerij/transfer_learning1/runs/3cnvexzo\" target=\"_blank\">https://wandb.ai/gijstimmerij/transfer_learning1/runs/3cnvexzo</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220611_161543-3cnvexzo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\gijst\\Documents\\Uni\\scriptie\\Transfer Learning\\wandb\\run-20220611_161652-2u5tlyjg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gijstimmerij/transfer_learning1/runs/2u5tlyjg\" target=\"_blank\">hardy-armadillo-100</a></strong> to <a href=\"https://wandb.ai/gijstimmerij/transfer_learning1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 5/13 [==========>...................] - ETA: 0s - loss: 201.5234 - mae: 171.7648 - root_mean_squared_error: 201.5234WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0266s vs `on_train_batch_end` time: 0.0566s). Check your callbacks.\n",
      "13/13 [==============================] - 6s 108ms/step - loss: 202.5136 - mae: 173.7394 - root_mean_squared_error: 203.7655 - val_loss: 106.8939 - val_mae: 95.6076 - val_root_mean_squared_error: 106.8939\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 204.4080 - mae: 174.6368 - root_mean_squared_error: 204.3101 - val_loss: 106.8939 - val_mae: 95.6076 - val_root_mean_squared_error: 106.8939\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.4839 - mae: 173.8932 - root_mean_squared_error: 201.9963 - val_loss: 106.8938 - val_mae: 95.6075 - val_root_mean_squared_error: 106.8938\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 202.0702 - mae: 173.7493 - root_mean_squared_error: 202.9641 - val_loss: 106.8938 - val_mae: 95.6074 - val_root_mean_squared_error: 106.8938\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 203.9881 - mae: 174.9904 - root_mean_squared_error: 205.1221 - val_loss: 106.8937 - val_mae: 95.6074 - val_root_mean_squared_error: 106.8937\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 201.0733 - mae: 172.8944 - root_mean_squared_error: 201.6516 - val_loss: 106.8937 - val_mae: 95.6074 - val_root_mean_squared_error: 106.8937\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 201.8512 - mae: 172.7081 - root_mean_squared_error: 201.4898 - val_loss: 106.8937 - val_mae: 95.6073 - val_root_mean_squared_error: 106.8937\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.5703 - mae: 174.0319 - root_mean_squared_error: 202.7006 - val_loss: 106.8936 - val_mae: 95.6073 - val_root_mean_squared_error: 106.8936\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.1493 - mae: 173.6405 - root_mean_squared_error: 202.1327 - val_loss: 106.8936 - val_mae: 95.6073 - val_root_mean_squared_error: 106.8936\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 205.5207 - mae: 176.5580 - root_mean_squared_error: 205.3390 - val_loss: 106.8936 - val_mae: 95.6073 - val_root_mean_squared_error: 106.8936\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 202.3973 - mae: 173.5624 - root_mean_squared_error: 203.2485 - val_loss: 106.8935 - val_mae: 95.6072 - val_root_mean_squared_error: 106.8935\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 201.3601 - mae: 172.7961 - root_mean_squared_error: 199.5702 - val_loss: 106.8935 - val_mae: 95.6072 - val_root_mean_squared_error: 106.8935\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 203.4435 - mae: 173.8863 - root_mean_squared_error: 206.0395 - val_loss: 106.8935 - val_mae: 95.6072 - val_root_mean_squared_error: 106.8935\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.4938 - mae: 174.0285 - root_mean_squared_error: 202.4252 - val_loss: 106.8935 - val_mae: 95.6072 - val_root_mean_squared_error: 106.8935\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 204.3974 - mae: 175.0232 - root_mean_squared_error: 205.2018 - val_loss: 106.8935 - val_mae: 95.6071 - val_root_mean_squared_error: 106.8935\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 203.0854 - mae: 174.3932 - root_mean_squared_error: 202.1170 - val_loss: 106.8934 - val_mae: 95.6071 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 205.8881 - mae: 175.7000 - root_mean_squared_error: 204.7731 - val_loss: 106.8934 - val_mae: 95.6071 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 199.7504 - mae: 171.2265 - root_mean_squared_error: 200.8093 - val_loss: 106.8934 - val_mae: 95.6071 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 203.5637 - mae: 173.8717 - root_mean_squared_error: 202.9173 - val_loss: 106.8934 - val_mae: 95.6071 - val_root_mean_squared_error: 106.8934\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 202.3776 - mae: 174.2092 - root_mean_squared_error: 203.4643 - val_loss: 106.8934 - val_mae: 95.6071 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.2448 - mae: 173.1587 - root_mean_squared_error: 203.4002 - val_loss: 106.8934 - val_mae: 95.6071 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 202.0726 - mae: 173.7529 - root_mean_squared_error: 202.5841 - val_loss: 106.8934 - val_mae: 95.6071 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 198.9104 - mae: 170.8129 - root_mean_squared_error: 199.5499 - val_loss: 106.8934 - val_mae: 95.6071 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 204.7695 - mae: 175.2037 - root_mean_squared_error: 204.0235 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.8372 - mae: 174.2505 - root_mean_squared_error: 201.4568 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 203.4404 - mae: 174.0300 - root_mean_squared_error: 203.1107 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.7574 - mae: 173.7033 - root_mean_squared_error: 203.9591 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.8729 - mae: 174.2563 - root_mean_squared_error: 200.5897 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 204.1272 - mae: 174.6156 - root_mean_squared_error: 203.1518 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 200.8962 - mae: 173.6606 - root_mean_squared_error: 198.0214 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.9785 - mae: 174.1681 - root_mean_squared_error: 202.4840 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 203.1273 - mae: 174.3977 - root_mean_squared_error: 204.3636 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 201.1002 - mae: 172.7665 - root_mean_squared_error: 201.8934 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 203.5427 - mae: 174.7288 - root_mean_squared_error: 204.5190 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.1603 - mae: 172.9806 - root_mean_squared_error: 202.5564 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.0553 - mae: 173.8689 - root_mean_squared_error: 202.7969 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 203.4185 - mae: 174.4620 - root_mean_squared_error: 204.9329 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 203.3744 - mae: 174.2105 - root_mean_squared_error: 203.3138 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 204.0057 - mae: 175.3370 - root_mean_squared_error: 201.9998 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.9028 - mae: 173.9131 - root_mean_squared_error: 204.4778 - val_loss: 106.8934 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8934\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 204.7693 - mae: 175.2010 - root_mean_squared_error: 205.0259 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.0650 - mae: 173.5789 - root_mean_squared_error: 201.3146 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.980232380322967e-11.\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.8093 - mae: 174.5543 - root_mean_squared_error: 204.9349 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 204.2322 - mae: 175.1394 - root_mean_squared_error: 203.9104 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 200.5484 - mae: 173.0095 - root_mean_squared_error: 198.4368 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 201.6916 - mae: 173.1090 - root_mean_squared_error: 201.1320 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 201.4412 - mae: 172.3951 - root_mean_squared_error: 202.6086 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.4901161901614834e-11.\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 203.4988 - mae: 174.4044 - root_mean_squared_error: 201.0173 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 204.5159 - mae: 175.3117 - root_mean_squared_error: 205.1407 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.3171 - mae: 173.8068 - root_mean_squared_error: 203.7624 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.0633 - mae: 173.7745 - root_mean_squared_error: 202.0743 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 203.5118 - mae: 174.5528 - root_mean_squared_error: 203.6727 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 7.450580950807417e-12.\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 201.2085 - mae: 172.6825 - root_mean_squared_error: 200.3512 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 205.9485 - mae: 175.9434 - root_mean_squared_error: 207.3279 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 203.0357 - mae: 174.1465 - root_mean_squared_error: 202.1406 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 201.9255 - mae: 173.1622 - root_mean_squared_error: 201.7232 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 204.4514 - mae: 174.6080 - root_mean_squared_error: 205.0440 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 3.725290475403709e-12.\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.0914 - mae: 173.5615 - root_mean_squared_error: 200.4456 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 203.8911 - mae: 174.6518 - root_mean_squared_error: 205.4367 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 204.4932 - mae: 175.2307 - root_mean_squared_error: 204.2809 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 203.2912 - mae: 174.1886 - root_mean_squared_error: 201.7581 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 201.7960 - mae: 174.2225 - root_mean_squared_error: 200.5211 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.8626452377018543e-12.\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 199.4254 - mae: 171.4396 - root_mean_squared_error: 199.5238 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.5625 - mae: 174.0704 - root_mean_squared_error: 202.6731 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 203.9499 - mae: 175.2382 - root_mean_squared_error: 203.0401 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 201.7034 - mae: 172.7478 - root_mean_squared_error: 200.8292 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.4707 - mae: 173.2722 - root_mean_squared_error: 202.8965 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 9.313226188509272e-13.\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 203.0139 - mae: 173.9163 - root_mean_squared_error: 203.7102 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.6551 - mae: 174.8045 - root_mean_squared_error: 202.7566 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 204.4266 - mae: 175.3575 - root_mean_squared_error: 204.7982 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 203.1476 - mae: 175.0204 - root_mean_squared_error: 201.8040 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 205.0746 - mae: 175.1039 - root_mean_squared_error: 204.8679 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 4.656613094254636e-13.\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 204.5244 - mae: 174.9331 - root_mean_squared_error: 205.6066 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 201.5035 - mae: 172.3273 - root_mean_squared_error: 201.0726 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 201.4146 - mae: 173.4832 - root_mean_squared_error: 201.9650 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.4266 - mae: 173.0711 - root_mean_squared_error: 204.0524 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 203.1044 - mae: 174.2988 - root_mean_squared_error: 201.9284 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 2.328306547127318e-13.\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 203.0231 - mae: 174.1849 - root_mean_squared_error: 202.4522 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 201.4459 - mae: 173.0907 - root_mean_squared_error: 200.6196 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 205.0184 - mae: 175.5500 - root_mean_squared_error: 204.0752 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 200.1945 - mae: 171.7695 - root_mean_squared_error: 199.5104 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 203.5848 - mae: 174.3561 - root_mean_squared_error: 203.6052 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.164153273563659e-13.\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 203.7751 - mae: 175.2345 - root_mean_squared_error: 203.5039 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.3493 - mae: 173.2676 - root_mean_squared_error: 203.0154 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 200.4037 - mae: 172.7305 - root_mean_squared_error: 201.5251 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 204.8641 - mae: 174.7453 - root_mean_squared_error: 205.5995 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 204.0625 - mae: 174.8198 - root_mean_squared_error: 204.6287 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 5.820766367818295e-14.\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.3971 - mae: 174.3491 - root_mean_squared_error: 203.0217 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 200.7111 - mae: 172.8000 - root_mean_squared_error: 199.0565 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.1481 - mae: 174.0991 - root_mean_squared_error: 201.9770 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 204.7547 - mae: 175.3002 - root_mean_squared_error: 203.2241 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 203.7227 - mae: 175.0735 - root_mean_squared_error: 202.4503 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 2.9103831839091474e-14.\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 203.9475 - mae: 174.5540 - root_mean_squared_error: 203.8753 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 202.9688 - mae: 174.2970 - root_mean_squared_error: 204.1744 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.9830 - mae: 173.6689 - root_mean_squared_error: 203.0207 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 202.8685 - mae: 173.6018 - root_mean_squared_error: 202.0012 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 205.2836 - mae: 176.0360 - root_mean_squared_error: 204.9147 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.4551915919545737e-14.\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 201.9335 - mae: 174.0697 - root_mean_squared_error: 203.3326 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 202.9254 - mae: 174.4801 - root_mean_squared_error: 202.2886 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 203.9439 - mae: 174.6954 - root_mean_squared_error: 204.4926 - val_loss: 106.8933 - val_mae: 95.6070 - val_root_mean_squared_error: 106.8933\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a319859c40486dbf005a29827b4aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.717 MB of 2.717 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▅▅▃▅▄▆▅▂▄▁▆▅▅▆▄▆▇▆▄▇▄█▄▆▅▅▅▅▇▄▅▄▆▄▆▃▆▅▇▆</td></tr><tr><td>mae</td><td>▅▅▄▅▅▅▆▂▄▁▅▆▅▆▅▇▇▇▄▇▅█▄▆▆▅▄▆▇▃▆▄▆▄▆▄▇▆█▆</td></tr><tr><td>root_mean_squared_error</td><td>▅▃▃▄▅▇▄▂▅▁▄▂▄▆▄▃▆▅▃▆▄█▃▆▃▄▄▄▆▃▃▂▅▄▆▁▄▅▆▆</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▇▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_root_mean_squared_error</td><td>█▇▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>33</td></tr><tr><td>best_val_loss</td><td>106.89335</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>203.94386</td></tr><tr><td>mae</td><td>174.69545</td></tr><tr><td>root_mean_squared_error</td><td>204.49257</td></tr><tr><td>val_loss</td><td>106.89335</td></tr><tr><td>val_mae</td><td>95.60703</td></tr><tr><td>val_root_mean_squared_error</td><td>106.89335</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hardy-armadillo-100</strong>: <a href=\"https://wandb.ai/gijstimmerij/transfer_learning1/runs/2u5tlyjg\" target=\"_blank\">https://wandb.ai/gijstimmerij/transfer_learning1/runs/2u5tlyjg</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220611_161652-2u5tlyjg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group = 'df4_reducedn10_inilr.0005_redlr_alltrain'\n",
    "swpX = swp_X_reduced\n",
    "swpy = swp_y_reduced.astype('float')\n",
    "adam = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "# adam = keras.optimizers.Adam()\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=5, verbose=1)\n",
    "for i in range(3):\n",
    "    model = keras.Sequential()\n",
    "    for layer in estimator.layers[:-1]:\n",
    "        model.add(layer)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.trainable = True\n",
    "    model.compile(loss=root_mean_squared_error, optimizer=adam,\n",
    "                  metrics=['mae', root_mean_squared_error])\n",
    "    run = wandb.init(project='transfer_learning1', entity='gijstimmerij',\n",
    "                     reinit=True, group=group)\n",
    "    history = model.fit(swpX, swpy, epochs=100, batch_size=200,\n",
    "                        validation_split=.05, callbacks=[WandbCallback(), reduce_lr])\n",
    "    run.name = f'{group}_{i+1}'\n",
    "    run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"models\\transfer_learning\\df4_n10_redlr_alltrain.h5\"\n",
    "estimator = load_model(model_path,custom_objects={'root_mean_squared_error': root_mean_squared_error,'TCN': TCN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 2s 8ms/step - loss: 58.6796 - mae: 55.7511 - root_mean_squared_error: 58.6823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[58.67958068847656, 55.75108337402344, 58.68227767944336]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(swp_X_test, swp_y_test.astype('float'), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2de1618ca4d8737d8b63b0b2c49d8fcc0ec5269c8d972158d185e980381db1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
