{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baselines.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKzZNYkML0-F",
        "outputId": "4369236d-a2cb-49d9-ce4d-b49fd6b472cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "from importlib.machinery import SourceFileLoader\n",
        "somemodule = SourceFileLoader('tcn', '/content/drive/MyDrive/Sriptie/RUL-prediction/keras-tcn-master/tcn/tcn.py').load_module()"
      ],
      "metadata": {
        "id": "atS7CnlxL2gw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import os\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.python.keras.layers.core import Activation\n",
        "from tensorflow.keras.models import Sequential,load_model, model_from_json\n",
        "\n",
        "from tcn import TCN"
      ],
      "metadata": {
        "id": "nH-i64LYL4EX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define paths\n",
        "output_path = '/content/drive/MyDrive/Sriptie/RUL-prediction/output-tcn-6'\n",
        "model_path = output_path+'/mode.h5'\n",
        "\n",
        "data_path = '/content/drive/MyDrive/Sriptie/RUL-prediction/Data/CMAPSSData/'\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "FKD-S0oSL42b"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################\n",
        "# Data Ingestion\n",
        "##################################\n",
        "\n",
        "# read training data - It is the aircraft engine run-to-failure data.\n",
        "train_df = pd.read_csv(data_path+'train_FD001.txt', sep=\" \", header=None)\n",
        "train_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\n",
        "train_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "\n",
        "train_df = train_df.sort_values(['id','cycle'])\n",
        "\n",
        "# read test data - It is the aircraft engine operating data without failure events recorded.\n",
        "test_df = pd.read_csv(data_path+'test_FD001.txt', sep=\" \", header=None)\n",
        "test_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\n",
        "test_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "\n",
        "# read ground truth data - It contains the information of true remaining cycles for each engine in the testing data.\n",
        "truth_df = pd.read_csv(data_path+'RUL_FD001.txt', sep=\" \", header=None)\n",
        "truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "3aonEho0L53w"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######\n",
        "# TRAIN set\n",
        "#######\n",
        "# Data Labeling - generate column RUL(Remaining Usefull Life or Time to Failure)\n",
        "rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id', 'max']\n",
        "train_df = train_df.merge(rul, on=['id'], how='left')\n",
        "train_df['RUL'] = train_df['max'] - train_df['cycle']\n",
        "train_df.drop('max', axis=1, inplace=True)\n",
        "\n",
        "# generate label columns for training data\n",
        "# we will only make use of \"label1\" for binary classification, \n",
        "# while trying to answer the question: is a specific engine going to fail within w1 cycles?\n",
        "w1 = 30\n",
        "w0 = 15\n",
        "train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n",
        "train_df['label2'] = train_df['label1']\n",
        "train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\n",
        "\n",
        "# MinMax normalization (from 0 to 1)\n",
        "train_df['cycle_norm'] = train_df['cycle']\n",
        "cols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
        "                             columns=cols_normalize, \n",
        "                             index=train_df.index)\n",
        "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "train_df = join_df.reindex(columns = train_df.columns)\n"
      ],
      "metadata": {
        "id": "5Tqcr3LJL6_R"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# TEST set\n",
        "######\n",
        "# MinMax normalization (from 0 to 1)\n",
        "test_df['cycle_norm'] = test_df['cycle']\n",
        "norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n",
        "                            columns=cols_normalize, \n",
        "                            index=test_df.index)\n",
        "test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
        "test_df = test_join_df.reindex(columns = test_df.columns)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "print(test_df.head())\n",
        "\n",
        "# We use the ground truth dataset to generate labels for the test data.\n",
        "# generate column max for test data\n",
        "rul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id', 'max']\n",
        "truth_df.columns = ['more']\n",
        "truth_df['id'] = truth_df.index + 1\n",
        "truth_df['max'] = rul['max'] + truth_df['more']\n",
        "truth_df.drop('more', axis=1, inplace=True)\n",
        "\n",
        "# generate RUL for test data\n",
        "test_df = test_df.merge(truth_df, on=['id'], how='left')\n",
        "test_df['RUL'] = test_df['max'] - test_df['cycle']\n",
        "test_df.drop('max', axis=1, inplace=True)\n",
        "\n",
        "# generate label columns w0 and w1 for test data\n",
        "test_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\n",
        "test_df['label2'] = test_df['label1']\n",
        "test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\n",
        "\n",
        "#test_df.to_csv('../../Dataset/PredictiveManteinanceEngineValidation.csv', encoding='utf-8',index = None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kgf6WbzL8Hl",
        "outputId": "47e56cca-0c07-4e3f-dfc6-245781ac6640"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
            "0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n",
            "1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n",
            "2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n",
            "3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n",
            "4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n",
            "\n",
            "    s5  ...       s13       s14       s15  s16       s17  s18  s19       s20  \\\n",
            "0  0.0  ...  0.220588  0.132160  0.308965  0.0  0.333333  0.0  0.0  0.558140   \n",
            "1  0.0  ...  0.264706  0.204768  0.213159  0.0  0.416667  0.0  0.0  0.682171   \n",
            "2  0.0  ...  0.220588  0.155640  0.458638  0.0  0.416667  0.0  0.0  0.728682   \n",
            "3  0.0  ...  0.250000  0.170090  0.257022  0.0  0.250000  0.0  0.0  0.666667   \n",
            "4  0.0  ...  0.220588  0.152751  0.300885  0.0  0.166667  0.0  0.0  0.658915   \n",
            "\n",
            "        s21  cycle_norm  \n",
            "0  0.661834     0.00000  \n",
            "1  0.686827     0.00277  \n",
            "2  0.721348     0.00554  \n",
            "3  0.662110     0.00831  \n",
            "4  0.716377     0.01108  \n",
            "\n",
            "[5 rows x 27 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "        \n",
        "def r2_keras(y_true, y_pred):\n",
        "    \"\"\"Coefficient of Determination \n",
        "    \"\"\"\n",
        "    SS_res =  K.sum(K.square( y_true - y_pred ))\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
      ],
      "metadata": {
        "id": "dI6C9f8NL-0e"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a  window size \n",
        "sequence_length = 64\n",
        "\n",
        "# function to reshape features into (samples, time steps, features) \n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    data_matrix = id_df[seq_cols].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_matrix[start:stop, :]\n",
        "        \n",
        "# pick the feature columns \n",
        "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
        "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
        "sequence_cols.extend(sensor_cols)\n",
        "\n",
        "val=list(gen_sequence(train_df[train_df['id']==1], sequence_length, sequence_cols))\n",
        "print(len(val))\n",
        "\n",
        "# generator for the sequences\n",
        "# transform each id of the train dataset in a sequence\n",
        "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) \n",
        "           for id in train_df['id'].unique())\n",
        "\n",
        "# generate sequences and convert to numpy array\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "print(seq_array.shape)\n",
        "\n",
        "# function to generate labels\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    data_matrix = id_df[label].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    return data_matrix[seq_length:num_elements, :]\n",
        "\n",
        "# generate labels\n",
        "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['RUL']) \n",
        "             for id in train_df['id'].unique()]\n",
        "\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "label_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2T_yjeIeZht",
        "outputId": "c135ad38-cb15-4a3f-ed0d-f5a7fc2408bd"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n",
            "(14231, 64, 25)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14231, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = train_df.pop(\"RUL\")\n",
        "y_test = test_df.pop(\"RUL\")"
      ],
      "metadata": {
        "id": "QGlx0HqCMDJT"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_list = train_df.columns.to_list()"
      ],
      "metadata": {
        "id": "9oYoY_AaNCon"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df[col_list]"
      ],
      "metadata": {
        "id": "B7Qdcs6BOFhH"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=1000)\n",
        "model.fit(train_df, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO5qvyYTMJER",
        "outputId": "965b841b-3a00-4b6f-d899-c0ac2eab18a1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(n_estimators=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = model.score(test_df, y_test)\n",
        "pred_rand_forest = model.predict(test_df)"
      ],
      "metadata": {
        "id": "zQqaYPNeMLBX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ],
      "metadata": {
        "id": "tF1L0TPnX8MH"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y_test, pred_rand_forest)\n",
        "rmse = mean_squared_error(y_test, pred_rand_forest, squared=False)"
      ],
      "metadata": {
        "id": "HF1a1wjBQAhZ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'r2_score: {r2}')\n",
        "print(f'mae: {mae}')\n",
        "print(f'rmse: {rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mB20xuSZh5w",
        "outputId": "c57cdbc9-8f2e-4827-9c4b-7826b8c3d405"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2_score: 0.23404816692269803\n",
            "mae: 39.031632712278565\n",
            "rmse: 51.616643060702685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "k_nn = KNeighborsRegressor()\n",
        "k_nn.fit(train_df, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtmqvELyMLyM",
        "outputId": "16ff5954-556b-4c7e-b2c3-04119caaca28"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
            "Feature names must be in the same order as they were in fit.\n",
            "\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12008537637982952"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_knn = k_nn.predict(test_df)"
      ],
      "metadata": {
        "id": "wwmoDjcUaE8j"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_knn = k_nn.score(test_df, y_test)\n",
        "mae_knn = mean_absolute_error(y_test, pred_knn)\n",
        "rmse_knn = mean_squared_error(y_test, pred_knn, squared=False)"
      ],
      "metadata": {
        "id": "Tszj33PJaRuV"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'r2_score: {r2_knn}')\n",
        "print(f'mae: {mae_knn}')\n",
        "print(f'rmse: {rmse_knn}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQtvdgOjafXi",
        "outputId": "2003c4d3-5440-4786-cf2d-e973dc585e1f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2_score: 0.12672196988862539\n",
            "mae: 43.51076664630421\n",
            "rmse: 55.11442661754337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression()\n",
        "reg.fit(train_df, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxrnEyKqMMfL",
        "outputId": "5f3e5fa2-8d20-4148-aa7c-56e2b03e3ac8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
            "Feature names must be in the same order as they were in fit.\n",
            "\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44265754331404505"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lin = reg.predict(test_df)"
      ],
      "metadata": {
        "id": "Ia5ptuIyaxmv"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_lin = reg.score(test_df, y_test)\n",
        "mae_lin = mean_absolute_error(y_test, pred_lin)\n",
        "rmse_lin = mean_squared_error(y_test, pred_lin, squared=False)"
      ],
      "metadata": {
        "id": "Mwsa2K2eaprg"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'r2_score: {r2_lin}')\n",
        "print(f'mae: {mae_lin}')\n",
        "print(f'rmse: {rmse_lin}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypheo6qdbGSK",
        "outputId": "7cc0b637-bc8b-4bf8-b960-0e84473739de"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2_score: 0.4637780519775502\n",
            "mae: 33.84126499515733\n",
            "rmse: 43.18782366156043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################################\n",
        "# EVALUATE ON TEST DATA\n",
        "##################################\n",
        "\n",
        "# We pick the last sequence for each id in the test data\n",
        "seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:] \n",
        "                       for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n",
        "\n",
        "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
        "print(\"seq_array_test_last\")\n",
        "print(seq_array_test_last.shape)\n",
        "\n",
        "# Similarly, we pick the labels\n",
        "#print(\"y_mask\")\n",
        "y_mask = [len(test_df[test_df['id']==id]) >= sequence_length for id in test_df['id'].unique()]\n",
        "label_array_test_last = test_df.groupby('id')['RUL'].nth(-1)[y_mask].values\n",
        "label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)\n",
        "print(label_array_test_last.shape)\n",
        "#print(\"label_array_test_last\")\n",
        "#print(label_array_test_last)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alXUvZFWe_3Z",
        "outputId": "b1e46a89-118c-48ab-e128-8f390b5a43df"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seq_array_test_last\n",
            "(88, 64, 25)\n",
            "(88, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################################\n",
        "# EVALUATE ON TEST DATA\n",
        "##################################\n",
        "#def evaluate_on_test_data(model_path,id,sequence_length ):\n",
        "dense_model_path = output_path+'/tcn_fuse_dense_model.h5'\n",
        "# We pick the last sequence for each id in the test data\n",
        "\n",
        "sequence_length = seq_array5.shape[1]\n",
        "# Similarly, we pick the labels\n",
        "\n",
        "y_mask = [len(test_df[test_df['id']==id]) >= sequence_length for id in test_df['id'].unique()]\n",
        "label_array_test_last = test_df.groupby('id')['RUL'].nth(-1)[y_mask].values\n",
        "label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)\n",
        "print(label_array_test_last.shape)\n",
        "#print(\"label_array_test_last\")\n",
        "#print(label_array_test_last)\n",
        "\n",
        "# if best iteration's model was saved then load and use it\n",
        "if os.path.isfile(dense_model_path):\n",
        "\n",
        "    # restore weights\n",
        "    estimator = load_model(dense_model_path,custom_objects={'r2_keras': r2_keras, 'root_mean_squared_error': root_mean_squared_error})\n",
        "\n",
        "    \n",
        "    # test metrics\n",
        "    scores_test = estimator.evaluate(seq_array_test_new, label_array_test_last, verbose=2)\n",
        "    print('\\nMAE: {}'.format(scores_test[1]))\n",
        "    print('\\nR^2: {}'.format(scores_test[2]))\n",
        "    print('\\nRMSE: {}'.format(scores_test[3]))\n",
        "\n",
        "    y_pred_test = estimator.predict(seq_array_test_new)\n",
        "    y_true_test = label_array_test_last\n",
        "\n",
        "    test_set = pd.DataFrame(y_pred_test)\n",
        "    test_set.to_csv(output_path+'/submit_test_fuse_dense.csv', index = None)\n",
        "\n",
        "\n",
        "\n",
        "    result = pd.DataFrame( columns = ['pred', 'true']) \n",
        "    result['pred'] = y_pred_test.flatten().round()\n",
        "    result['true'] = y_true_test.flatten()\n",
        "    result.sort_values(by='true', inplace=True)\n",
        "    # Plot in blue color the predicted data and in orange color the\n",
        "    # actual data to verify visually the accuracy of the model.\n",
        "        \n",
        "    x = np.arange(len(y_pred_test))\n",
        "    width = 0.35  # the width of the bars\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(100, 50))\n",
        "    rects1 = ax.bar(x - width/2,result['pred'], width, label='predicted')\n",
        "    rects2 = ax.bar(x + width/2,result['true'], width, label='true')\n",
        "\n",
        "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "    ax.set_ylabel('value')\n",
        "    ax.set_title('prediction')\n",
        "    ax.set_xticks(x)\n",
        "    ax.legend()\n",
        "\n",
        "\n",
        "    def autolabel(rects):\n",
        "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "        for rect in rects:\n",
        "            height = rect.get_height()\n",
        "            ax.annotate('{}'.format(height),\n",
        "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                        xytext=(0, 3),  # 3 points vertical offset\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom')\n",
        "\n",
        "\n",
        "    autolabel(rects1)\n",
        "    autolabel(rects2)\n",
        "\n",
        "    plt.show()\n",
        "    fig.savefig(output_path+\"/model_fuse_dense_verify_bar.png\")"
      ],
      "metadata": {
        "id": "HFCz89iWbJiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_model_path = output_path+'/tcn_fuse_dense_model.h5'\n",
        "estimator = load_model(dense_model_path,custom_objects={'r2_keras': r2_keras, 'root_mean_squared_error': root_mean_squared_error})\n"
      ],
      "metadata": {
        "id": "cKA21ruob9C5"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_test = estimator.evaluate(seq_array_test_last, label_array_test_last, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "b0ay-yL8cOxd",
        "outputId": "562db2ac-86bc-4fbd-8a5b-1e7e5d532f6c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-ad1a301f8952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_array_test_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_array_test_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_10\" is incompatible with the layer: expected shape=(None, 30), found shape=(None, 64, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pbSi2x56cfBg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}